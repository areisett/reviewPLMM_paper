
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The objective of many genetic studies is to accurately identify variants associated with complex traits or disease, and to estimate the effects of those variants. Such information is valuable for assessing an individual's risk of developing a particular condition, elucidating the underlying genetic architecture of a trait or disease, and identifying potential drug targets. However, this effort may be hindered by several factors such as non-independent samples, large numbers of variants, and linkage disequilibrium (LD). 

% \anna{keep this for later use when talking about genetic background?} Genetic variants are often correlated with each other such that univariate testing may be prone to false positives and biased estimates. When a genetic variant of interest is highly correlated with others, the effects of these will be attributed to the variant in question. This may result in causal SNPs being removed from analysis, so that only SNPs in LD with the causal loci, as opposed to the causal loci themselves, can be identified and their effects estimated. 

One method for analyzing data in the presence of correlated loci is LD pruning, which involves sequentially thinning SNPs, so that only those correlated with each other below some desired threshold are used in modeling and testing procedures. LD pruning can be an important preprocessing step in a GWAS analysis, for which there exist a variety of algorithms and methods. An alternative solution to the problem of LD is the use of multivariate methods such as multiple linear regression, which adjusts for and estimates the effects of numerous variants simultaneously. However, classical approaches rely on collecting data with more observations than unknown parameters. This is typically infeasible in genome-wide studies where the number of features greatly exceeds the number of observations. Penalized regression methods make such problems tractable by constraining the solution space of coefficient estimates. The Lasso is a widely used penalized regression method \citep{tibshirani1996regression}. It relies on an assumption of sparsity, which allows coefficient estimation and variable selection to be accomplished simultaneously. It also provides considerable computational advantages that scale up well to very large data sets. These features make the Lasso attractive for the analysis of high-dimensional genetic data where identifying a list of variants most highly associated with a particular trait is often of interest.

As with multiple linear regression models, Lasso penalized regression assumes independent observations and uncorrelated errors. In the presence of population structure or cryptic relatedness, however, samples are correlated, violating this assumption. If unaccounted for, this dependency can result in the identification of spurious associations. Though methods to correct for population stratification and cryptic relatedness have been extensively investigated, until recently the majority of this work has focused on plant and animal breeding data, much of which is experimentally controlled \citep{Amin2007, hoffman2013correcting, price2006principal, Rakitsch2012, bhatnagar2019simultaneous, Sillanpaeae2011}. While many standard correction techniques may in principal be applied to human genetic data, their performance has not been well-studied within the context of human ancestry and non-experimental conditions \citep{lawson2019population, barton2019population}.  

One reason that population stratification warrants such concern in genetic studies is that due to ethnic and geographic segregation, population stratification tends to be associated with differing environmental exposures and cultural practices \citep{thornton2015statistical, browning2011population}.  In other words, random genetic variation is likely to be correlated with non-genetic factors that also influence the trait of interest, thereby confounding the genotype-phenotype relationship and leading to spurious associations and biased estimates of SNP effects. Biased estimates of this nature severely hinder prediction and understanding differences among populations \citep{barton2019population}. Although bias at individual loci may be small, this bias becomes magnified when aggregated across thousands of SNPs, as is done when calculating polygenic risk scores \citep{barton2019population, peterson2019genome}.

In order to clarify and emphasize the importance of the subtle distinction between population structure and environmental heterogeneity, we present a detailed review of relevant concepts and methods. The remainder of this paper is organized as follows. In section \ref{sec:background} we provide a summary of the causes and consequences of structure in the genetic data of seemingly unrelated individuals and formally define terminology used throughout this paper. We emphasize that confounding due to population structure, frequently cited as a driver of spurious associations, is a function of environmental heterogeneity, where genetic data serves as a proxy for differential environmental exposures \citep{Sillanpaeae2011, sul2018population, vilhjalmsson2012nature, barton2019population}. In so doing, we refine the definition of confounding due to population structure in terms of a non-genetic mechanism. In addition, we briefly review historical methods of correcting for population stratification and relatedness. In section \ref{sec:methods} we provide a detailed review of the two most prevalent multivariate methods of adjusting for population stratification and relatedness at present: PCA adjusted lasso penalized regression (PC-Lasso) and lasso penalized multivariate LMMs (LMM-Lasso). We review the statistical details of these methods as well as the consequences \pb{do we review \emph{consequences} in section 3?} \anna{tbd} of the ways in which they attempt to correct for population structure and environmental heterogeneity. In section \ref{sec:results}, we illustrate the concepts described in section \ref{sec:methods} via simulation studies, where the data-generating mechanism formally differentiates between population structure and environmental heterogeneity. In addition, these results identify scenarios where particular methods may be most and least effective in accurately estimating the effect sizes of observed SNPs in the presence of unobserved confounding.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background} \label{sec:background}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%------------------------------%
\subsection{Structure in genetic data}

Population structure is a common phenomenon in genetic data. Varying levels of relatedness are almost always present among genetic samples, even in samples of unrelated individuals and seemingly homogeneous populations. For example, European American, Han Chinese, and most recently, cohorts within the UK Biobank data have been shown to exhibit patterns of population and geographic structure despiet their seemingly similar subjects \citep{campbell2005demonstrating, xu2009genomic, chen2009genetic, haworth2019apparent}.

Population structure is defined by the existence of allele frequency differences that define sub-populations and is driven by the combined effects of evolutionary processes such as genetic drift, migration, demographic history, and natural selection \citep{gibson2015primer, tibayrenc2017genetics}. Population structure is broadly categorized based on whether it describes recent or ancient relatedness. Ancient relatedness describes the presence of a common ancestor many generations previously. The presence of distinct ancestry groups with different allele frequencies in a sample is known as \textbf{population stratification}. Recent relatedness describes the sharing of a common ancestor only several generations previously. Pedigree-based methods may be used to explicitly model recent relatedness if familial relationships are known. In this absence of known familial relationships, recent relatedness is referred to as \textbf{cryptic relatedness.} In this review we focus on methods to account for unobserved relatedness such as population stratification and cryptic relatedness. 

Throughout this paper, the terms \textbf{population structure} and \textbf{structured population} will be used to describe a sample of individuals in which population stratification, cryptic relatedness, or both are present. Population stratification in particular has been of great concern in genetic studies due to its potential to lead to spurious associations when population structure is associated with differences in both allele frequency and the trait or disease \citep{gibson2015primer}. This phenomenon is commonly described as \textbf{confounding due to population stratification}. The mechanism of this phenomenon warrants some discussion as it is often overlooked that population structure in and of itself does not confound the genotype-phenotype relationship. While population structure may directly affect observed allele frequencies, there must also exist some non-genetic mechanism by which population stratification affects the phenotype, namely, the environment \citep{barton2019population, vilhjalmsson2012nature}.


%------------------------------%
\subsection{Motivating example}

As an example, consider a genome wide association study (GWAS) to assess genetic variants associated with lung cancer in a sample comprised of subjects from two distinct subpopulations, A and B. Assume the minor allele of SNP $X$ is present with higher frequency in subpopulation A compared to subpopulation B, but has no direct effect on lung cancer. Also suppose these subpopulations are geographically segregated in a such a way that subpopulation A is exposed to good air quality, and subpopulation B to poor air quality, and that air quality does have a direct effect on lung cancer. A GWAS of data from these subpopulations would find SNP $X$ to be significantly associated with lung cancer. This spurious association is not identified because of the presence of population stratification itself, but because that stratification is related to a causal environmental exposure. Indeed, if subpopulations A and B were not subject to different air qualities, all else being equal, SNP $X$ would not be found to be associated with the phenotype.

% \anna{description of DAG below, in reference to previous one}

This mechanism of environmental confounding is summarized in the directed acyclic graph displayed in Figure \ref{fig:ps_env}. The undirected dashed line between population stratification and environmental exposure indicates that while we assume these elements are correlated, we do not assume any causal direction. Otherwise stated, we do not assume that environmental factors directly influence population-specific allele frequencies, or vice versa, only that the two may be related. In the context of our air quality example, this means that we assume air quality is not directly altering individuals' allele frequencies, nor are allele frequencies causing individuals to move to regions of better or worse air quality. Genetic relatedness and environmental effects may become associated over time for any number of complex reasons beyond the scope of this paper. However, as we will discuss, many methods of correcting for population structure rely on this relationship and do not formally differentiate between effects of population structure and those of environment. Such methods assume that genetic relatedness serves as an accurate proxy for environmental exposures, which may or may not be the case depending on the exposure and population in question. \pb{is this an important point?} \anna{hmm... maybe? robust to this assumption: if it's not a good proxy it's not going to cause confounding}

\begin{figure}[H]
\centering
\begin{tikzpicture}
    \node (1) at (0,0) {Population Stratification};
    \node (2) [right = of 1] {Environment};
    \node (3) [below = of 1] {Observbed SNPs};
    \node (4) [below = of 2] {Phenotype};
    \path[bidirected, -] (1) edge (2);
    \path (1) edge (3);
    \path (2) edge (4);
    \path (3) edge (4);
\end{tikzpicture}
\caption{Directed acyclic graph (DAG) of confounding due to population structure.}
\label{fig:ps_env}
\end{figure}

An additional source of confounding in genetic studies that we will briefly mention is that of confounding due to genetic background. This occurs in univariate association methods when a non-causal SNP is tested for association with a trait of interest, and that SNP is correlated with a causal SNP. As \citet{vilhjalmsson2012nature} note, any trait that has some genetic basis will be subject to genetic background effects, just as traits that are influenced by the environment may be subject to environmental confounding. Given the importance of both genetic and environmental contributions to many complex phenotypes, both genetic background and environmental confounding are important factors in our ability to identify true causal genetic relationships between SNPs and phenotype. LD pruning is commonly employed to reduce confounding due to genetic background in univariate association testing. However, we will focus on methods which address this via genomewide multivariate analysis.

%------------------------------%
\subsection{Correcting for population structure}

One of the first methods to address the problem of confounding due to population structure is the genomic control (GC) method. GC is a univariate testing procedure which modifies a test statistic by a deflation factor. This deflation factor attempts to quantify and remove the effect of population structure on the distribution of the appropriate test statistic, and is estimated using loci independent of the phenotype of interest and the loci being tested for association \citep{devlin1999genomic, bacanu2000power, wang2009testing}. However, this deflation factor has been reported to be sensitive to the nature and quantity of the loci used to estimate it \citep{hellwege2017population, marchini2004effects}. Additionally, GC does not correct effect size estimates, so resulting coefficient estimates will be unreliable after GC is applied, even if their corresponding test statistics and p-values have been appropriately adjusted \citep{hellwege2017population}.

New statistical methods to control for the effects of confounding due to population stratification have proliferated as computational advances have allowed for the analysis of genetic data from large cohorts. Many of these methods attempt to block the causal pathway between population structure and observed SNP data. This is illustrated by the blocked arrow in Figure \ref{fig:ps_env_block}. As the figure shows, these methods do not directly address the environmental component of confounding due to population structure. Nevertheless, they may be effective in controlling confounding by indirectly blocking the causal pathway between the environment and observed SNPs. 

\begin{figure}[H]
\centering
\begin{tikzpicture}
    \node (1) at (0,0) {Population Stratification};
    \node (2) [right = of 1] {Environment};
    \node (3) [below = of 1] {Observbed SNPs};
    \node (4) [below = of 2] {Phenotype};
    \path[bidirected, -] (1) edge (2);
    \path[magenta, line width = 0.5] (1) edge (3);
    \path (2) edge (4);
    \path (3) edge (4);
    \tkzMarkSegment[color=magenta,pos=.5,mark=x](1,3)
\end{tikzpicture}
\caption{The causal pathway between the environment and observed SNPs may be indirectly blocked by many methods that attempt to reduce confounding due to population structure.}
\label{fig:ps_env_block}
\end{figure}

Whether or not such methods are effective at reducing confounding effects depends upon whether population structure can be accurately inferred, and if population structure is a good proxy for environmental effects. In the presence of environmental heterogeneity which affects the phenotype of interest, and which is not well-approximated by inferred population structure, SNP-phenotype associations will not be confounded. This is due to the absence of a causal pathway between population stratification and environment, as depicted in Figure \ref{fig:ps_env_block2}. In such a scenario, failing to account for unobserved environmental effects is likely to result in greater residual variability, however, SNP effect estimates will be unbiased \citep{greenland1999causal}. We will return to this idea and its mathematical justification in section \ref{sec:methods}. 

\begin{figure}[H]
\centering
\begin{tikzpicture}
    \node (1) at (0,0) {Population Stratification};
    \node (2) [right = of 1] {Environment};
    \node (3) [below = of 1] {Observbed SNPs};
    \node (4) [below = of 2] {Phenotype};
    \path[bidirected, -, magenta] (1) edge (2);
    \path (1) edge (3);
    \path (2) edge (4);
    \path (3) edge (4);
    \tkzMarkSegment[color=magenta,pos=.5,mark=x](1,2)
\end{tikzpicture}
\caption{The causal pathway between the environment and observed SNPs may be blocked if genetic information does not serve as an accurate proxy for it.}
\label{fig:ps_env_block2}
\end{figure}

Assuming for now that population structure is a good proxy for environmental effects, we return to our consideration of methods that attempt to control for confounding via the mechanism depicted in Figure \ref{fig:ps_env_block}. Such methods include LMMs, principal-component-based approaches, and stratified analyses. Stratified analyses refer to a general class of methods which attempt to infer subject membership within a discrete number of nonoverlapping subpopulations. Subsequent analyses are conducted within each subpopulation, and the subpopulation-specific results may then be combined via meta-analysis \citep{pritchard1999use, pritchard2000association}. By partitioning the overall sample size in this manner, the structured association method is particularly vulnerable to a loss of power. Additionally, it relies on the assumption that these subpopulations are distinct and nonoveralapping. This assumption may not accurately reflect the characteristics of a particular sample, such as one consisting of admixed populations, or recent relatedness. Considered in the context of our air quality example, rather than the existence of two subpopulations with exposure to either good or bad air quality, there may also be individuals who fall between these two extremes and are characterized by continuously varying relatedness and a gradient of air quality. By clustering those individuals within in one subpopulation or another we lose information about their more fine-grained, subtle relatedness.

Another approach is to create an approximation of population structure using surrogate variables, and to adjust for these as an additional model covariates. Principal component-adjustment (PC-adjustment) methods use the first several left singular vectors of a pairwise similarity matrix as these surrogate variables \citep{price2006principal}. This approach may be used in univariate or multivariate frameworks, and allows for analysis on the entirety of a structured sample. 

% rely on a pair-wise similarity matrix
Like PC-adjustment methods, LMMs utilize the left singular vectors of a similarity matrix to estimate and subsequently correct for relatedness among subjects. In an LMM, however, these left singular vectors are treated as random, rather than fixed effects. Additionally, the term LMM has been used to describe a number of distinct but related procedures for analyzing structured genetic data which differ in their objectives and methods. There are two main objectives of LMMs used in a structured genetic context: estimating narrow-sense heritability, and estimating individual SNP effects.

Among LMM methods that aim to estimate heritability, the most well-known example is genome-wide complex trait analysis (GCTA) \citep{yang2011gcta}. In this framework, all observed SNPs are treated as random effects. These effects are integrated out in order to estimate a genetic variance component, which in turn, is used to quantify the total narrow-sense heritability of a trait \citep{yang2010common}.

LMMs can also be used to estimate SNP effects, and this can be done in either a univariate or multivariate manner. Univariate approaches attempt to estimate the marginal effect of a SNP on the phenotype and assess the statistical significance of SNP-phenotype associations while controlling for population structure by modeling it as a random effect using a genetic similarity matrix \citep{yu2006unified, kang2010variance, kang2008efficient}. However, as with all univariate testing approaches, univariate LMM implementations are prone to spurious associations and biased effect estimates in the presence of LD. 

Multivariate mixed model approaches reduce these problems by modeling the relationship between a phenotype of interest and all SNPs simultaneously via penalized regression, while correcting for dependent error structures  \citep{Rakitsch2012, bhatnagar2019simultaneous}. This approach assumes there are a relatively small number of SNPs associated with the phenotype of interest that have large effect sizes. These SNPs will be included in the model as both fixed and random effects, while SNPs with smaller effect sizes are modeled only as part of the random effect in order to control for dependent errors due to relatedness and sample structure. 

The remainder of this review will focus on the performance of such multivariate Lasso-penalized methods for the analysis of continuous, normally distributed outcomes. Specifically, PC-adjustment and LMM methods, which we will refer to as PC-Lasso and LMM-Lasso, respectively. We consider two similar implementations of the LMM-Lasso method, one developed by \citet{Rakitsch2012} and a more recent implementation from \citet{bhatnagar2019simultaneous}. Subsequent references to LMM-Lasso apply to both implementations, unless otherwise stated. Where necessary, we will differentiate between these implementations by referring to them as LMM-Lasso-Rakitsch and LMM-Lasso-ggmix, respectively. 

Several studies have shown that LMMs outperform PC-adjustment methods in the univariate framework \citep{wang2013analytical, kang2010variance, zhao2007arabidopsis}. However, to the best of our knowledge this is the only comprehensive review and comparison of these methods in a penalized multivariate framework and using a simulation scheme motivated by human genetic relatedness and the environmental mechanism of confounding due to population structure.\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods} \label{sec:methods}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%------------------------------%
\subsection{Model}

To describe and compare PC-Lasso and LMM-Lasso, we consider an $n \times p$ matrix of genotype data $\boldsymbol{G}$ for $n$ subjects and $p$ SNPs, where each $G_{i,j} \in \{ 0, 1, 2 \}$ enumerates the number of allele copies subject $i$ has for SNP $j$. We denote the standardized version of this genotype matrix as $\bX$, where each $X_{ij} = (G_{ij} - 2 p_j) / \sqrt{2 p_j (1 - p_j)}$ and $p_j$ is the minor allele frequency (MAF) of SNP $j$ \citep{zhang2015principal, price2006principal}. Additionally, $\bX_0$ represents an $n \times p_0$ matrix of unpenalized covariates and the intercept. Thus, at a minimum, $\bX_0$ will be an $n \times 1$ vector of 1s to represent the intercept, in which case $\bbeta_0 \equiv \beta_0$ is the scalar intercept. However, $\bX_0$ may additionally include covariates such as age and sex, which are of interest to include in the model without penalty. We assume that the $n \times 1$ vector of continuous phenotype values, $\by$, can be expressed as the sum of these covariates, additive SNP effects, environmental effects, and observational noise, and consider the linear mixed model,
\begin{equation}
    \label{eqn:model}
    \by = \bX_0 \bbeta_0 + \bX\bbeta + \bZ\bgamma + \beps
\end{equation}
where $\bbeta_0$ is a $p_0 \times 1$ vector which includes the intercept term and the effects of any unpenalized covariates, $\bbeta$ is a $p \times 1$ vector of SNP effects, $\bgamma$ is a $q \times 1$ vector of environmental effects, $\bZ$ is an $n \times q$ matrix that allocates environmental effects among subjects, and $\beps \sim N(\boldsymbol{0}, \sigmaee \bI_n)$. Often it is assumed that subjects belong to $q \le p$ subpopulations, and $\bZ$ is a corresponding incidence matrix of 0s and 1s. However, as we will discuss, this is not the only possibility.

LMM-Lasso relies on matrix decompositions of $\bX$ and the realized relationship matrix (RRM), $\bK = p^{-1} \bX \bX^\T$, which describes the pair-wise genetic similarity among subjects \citep{hayes2009increased}. Using the singular value decomposition (SVD) of the standardized genotype matrix, we can derive the spectral decomposition of the RRM: 

\begin{align}
    \label{eqn:k}
    \bK &= \frac{1}{p} \bX \bX^\T \nonumber \\
                   &= \frac{1}{p} \bU \bD^2 \bU^\T \nonumber \\
                   &= \frac{1}{p} \bU \bD (\bU \bD)^\T \nonumber \\
                   &\propto \bR \bR^\T,
\end{align}
where $\bD^2$ is an $n \times n$ diagonal matrix containing the $k$ nonzero eigenvalues of $\bK$ (equivalently, the $k$ nonzero squared singular values of $\bX$) on the top-left diagonal, followed by $n - k$ zeroes on the bottom-right diagonal, and $\bU$ is the corresponding $n \times n$ orthonormal matrix of the left eigenvectors of $\bK$ (equivalently, the left singular vectors of $\bX$.) The first $k$ columns of $\bU$ correspond to the nonzero eigenvalues of $\bK$ (squared singular values of $\bX$.) The columns of $\bR$ are therefore proportional to the principal components of $\bK$. 

%------------------------------%
\subsection{PC-Lasso}
PC-Lasso uses the first $k$ principal components of $\bK$ to approximate $\bZ\bgamma$ and includes them in the model as unpenalized covariates. It has been shown \citep{hoffman2013correcting} that this corresponds to the regression model
\begin{equation}
    \label{eqn:pca_reg}
    \by = \bX_0\bbeta_0 + \bX\bbeta + \bU_{1:k}\boldsymbol{\alpha} + \beps 
\end{equation}
where $\bU_{1:k}$ is the $n \times k$ matrix of principal component vectors, $\boldsymbol{\alpha}$ their corresponding $k \times 1$ coefficient vector, and all other parameters are as defined in equation \eqref{eqn:model}. In a penalized regression framework, this model yields the objective function
\begin{equation}
    \label{eqn:pca_obj}
    Q(\bbeta, \boldsymbol{\alpha}|\bX, \by) = \frac{1}{2n} ||\by - \bX_0\bbeta_0 - \bX \bbeta- \bU_{1:k}\boldsymbol{\alpha}||_2^2 + \lambda || \bbeta ||_1
\end{equation}
where $\lambda$ is a tuning parameter, and $|| \boldsymbol{\beta} ||_1 = \sum_{j=1}^p |\beta_j|$ denotes the $\ell_1$ norm of the regression coefficients, and $||.||_2$ the $\ell_2$ norm. Note that the principal component regression coefficients, $\boldsymbol{\alpha}$, are not included in the penalty term. 

%------------------------------%
\subsection{LMM-Lasso}

Conversely, LMM-Lasso models $\bZ\bgamma$ as a random effect assuming $\bgamma \sim N\left(\boldsymbol{0}, p^{-1} \sigmagg \bI_p \right).$  Typically, $\bZ$ is not observed directly, and a common convention is to assume $\bZ = \bX$ \citep{wang2018multiplex, lippert2011fast, yang2014advantages}. This results in the LMM regression model
\begin{equation}
    \label{eqn:lmm_reg}
    \by = \bX_0\bbeta_0 + \bX\bbeta + \bX\bgamma+ \beps,
\end{equation}
where we assume $\beps \independent \bX\bgamma$. Rather than assuming anything about $\bgamma$ directly, an equivalent representation paramaterizes the model in terms of $\bu=\bX\bgamma$ where $\bu \sim N(\boldsymbol{0}, \sigmagg \bK)$, and yields the equivalent model
\begin{equation}
    \label{eqn:lmm_reg_u}
    \by = \bX_0\bbeta_0 + \bX\bbeta + \bu + \beps.
\end{equation}
We will first derive the LMM-Lasso objective function in the absence of unpenalized covariates for the sake of notational simplicity.

Following equations \eqref{eqn:lmm_reg} and \eqref{eqn:lmm_reg_u}, in the absence of unpenalized covariates the LMM assumes $\by \sim N(\bX \bbeta, \bV)$, where $\bV = \sigmagg \textbf{K} + \sigmaee \textbf{I}$. LMM-Lasso uses \anna{an estimate of} the covariance structure of the errors and properties of the multivariate normal distribution to transform the original data and diagonalize the errors in a manner akin to generlized least squares (GLS). Specifically, left-multiplying the original data by $\bV^{-1/2}$ yields 

\begin{equation}
\label{eqn:rtY_distn}
\bV^{-\frac{1}{2}}\by \sim N(\bV^{-\frac{1}{2}} \bX \bbeta, \bI)
\end{equation}
and a regular \anna{vanilla, naive, regular?} Lasso model can be fit on the transformed data, ($\bV^{-\frac{1}{2}}\bX, \bV^{-\frac{1}{2}}\by$). \anna{...however, as Karl Rohe paper shows, GLS does not completely translate to penalized regression...comment on this?}

Using the spectral decomposition of $\bK$ described in equation \eqref{eqn:k}, we can gain further insight into the mechanism of this transformation. Note that $\bV^{-1}$ can be expressed using the following matrix factorization 
\begin{align*}
    \bV^{-1} &= (\sigmagg \bK + \sigmaee \bI)^{-1}\\
    &=(\sigmagg \bU \bD^2 \bU^\T + \sigmaee \bU \bU^\T)^{-1}\\
    &= (\bU (\sigmagg \bD^2 + \sigmaee \bI) \bU^\T)^{-1}\\
    &=\bU (\sigmagg \bD^2 + \sigmaee \bI)^{-1} \bU^\T\\
    &=\bU \bW^2 \bU^\T.
\end{align*}
By incorporating these decompositions, the transformed data can be expressed as $\bW \bXT$ and $\bW \byT$, respectively, where $\bXT = \bU^\T \bX$ and $\byT = \bU^\T \by$, where $\bW = \text{diag}\{w_1, ... w_n\}$ and $w_i$ corresponds to the square root of the $i$th element of the diagonal matrix $(\sigmagg \bD^2 + \sigmaee \bI)^{-1}$. Together, this yields the objective function
\begin{equation}
\label{eqn:lmm_obj}
Q(\bbeta | \bXT, \byT, \bW) = || \bW (\byT - \bXT \bbeta)||_2^2 + \lambda || \bbeta ||_1.
\end{equation}
In the presence of an intercept and unpenalized covariates, \eqref{eqn:rtY_distn} becomes 
\begin{equation}
\bV^{-\frac{1}{2}}\by \sim N\left(\bV^{-\frac{1}{2}} \bX{^\prime} \bbeta{^\prime}, \bI \right)
\end{equation}
where $\bX{^\prime} = \begin{bmatrix} \bX_0 & \bX \end{bmatrix}$ and $\bbeta{^\prime} = \begin{bmatrix} \bbeta_0^\T & \bbeta^\T \end{bmatrix}^\T$. This in turn leads to a new version of \eqref{eqn:lmm_obj}, our objective function,  
\begin{equation}
Q(\bbeta | \bXT{^\prime}, \byT, \bW) = || \bW (\byT - \bXT{^\prime} \bbeta{^\prime})||_2^2 + \lambda || \bbeta ||_1
\end{equation}
where $\bXT{^\prime} = \bU^\T \bX{^\prime}$, so that all of the data are transformed, but only the elements of $\bbeta{^\prime}$ corresponing to SNPs are penalized. 

%------------------------------%
\subsubsection{LMM-Lasso variants}
\label{sec:rak-ggmix}

We have so far used the term $\bW$ to describe the LMM-Lasso method. However, the form of $\bW$ and method of variance component estimation differs between LMM-Lasso-Rakitsch and LMM-Lasso-ggmix. LMM-Lasso-Rakitsch uses a two-step procedure for estimating the variance components, $\sigmaee$ and $\delta := \sigmaee / \sigmagg$ \citep{Rakitsch2012}. These variance components and the corresponding weights are estimated once under the assumption of a null model. A Lasso model can then be fit on the transformed data to estimate $\boldsymbol{\beta}$ using standard software for coordinate descent, such as \texttt{glmnet} \citep{glmnet} or \texttt{ncvreg} \citep{ncvreg}. LMM-Lasso-ggmix iteratively updates $\widehat{\boldsymbol{\beta}}$ and the variance components via a block coordinate descent algorithm \citep{bhatnagar2019simultaneous}. This iterative update scheme necessitates the use of the corresponding \texttt{R} package \texttt{ggmix} \citep{ggmix}. We postpone further discussion of the differences between these methods to section \ref{sec:results}.

%------------------------------%
% \subsubsection{\anna{Intuition from GLS (?) p-values and SEs in response to rotation?}}


%------------------------------%
\subsection{Relationship between PC-Lasso and LMM-Lasso}

It has been shown that the random effect formulation of model \eqref{eqn:model} used by LMM-Lasso can be equivalently expressed in terms of fixed effects. \citet{zhang2015principal} derived this equivalence using a probabilistic PCA formulation, while \citet{hoffman2013correcting} used the singular value decomposition of $\bX$, and the decomposition of $\bK$ \anna{which we briefly review here...}

Thus, whether modeled as a fixed or random effect, the underlying effect of $\bZ \bgamma$ on phenotype remains the same, but its treatment as a fixed or random effect has important implications in terms of model fitting and estimation. Modeling unobserved confounding using fixed effects requires estimation of $p_0 + p + k$ parameters, compared to the $p_0 + p + 2$ required of an LMM, which may result in a loss of power \citep{zhang2015principal}. Additionally, when modeling $\bZ \bgamma$ using fixed effects, determining the appropriate number of principal components to adjust for is non-trivial, and has been the subject of numerous studies \citep{patterson2006population, zhao2018practical}. It has been shown that including too many or too few principal components can result in power loss or increased Type I errors, respectively \citep{zhang2015principal}. Nevertheless, a common practice is to include the ten largest principal components in the analysis \citep{zhao2018practical}. This is the implementation of PC-Lasso throughout Section \ref{sec:results}.



%------------------------------%
\subsection{Simulating environmental confounding}

In carrying out simulation studies of the LMM regression model \eqref{eqn:lmm_reg}, a common practice is to draw a new value of the quantity $\bX\bgamma$ from a $N(\boldsymbol{0}, \sigmagg \bK)$ for each replication of the analysis \citep{Rakitsch2012, bhatnagar2019simultaneous}.  We argue that this is somewhat misleading from the perspective of understanding the statistical properties of the method. Averaging over situations in which the environmental confounding is constantly changing direction and magnitude is inconsistent with the confounding environmental effects. This has the effect of ``washing out'' bias in $\bbetaHat$, which is of interest, while inflating the variance. To illustrate this concept, consider the low-dimensional ordinary least squares (OLS) estimates of $\bbeta$ based on model \eqref{eqn:lmm_reg} where, without loss of generatlity, we assume $\bX_0 \bbeta_0 = \boldsymbol{0}$ for ease of notation: 
\begin{align}
    \mathbb{E}(\bbetaHat) &= (\bX^\T \bX)^{-1} \bX^\T \mathbb{E}(\by) \notag \\
    &=  (\bX^\T \bX)^{-1} \bX^\T \mathbb{E}(\bX\bbeta + \bX\bgamma + \beps) \label{eqn:expectation}\\
    &\quad \notag\\
    \mathbb{V}(\bbetaHat) &= (\bX^\T \bX)^{-1} \bX^\T \mathbb{V}(\by) \notag\\
    &=  (\bX^\T \bX)^{-1} \bX^\T \mathbb{V}(\bX\bbeta + \bX\bgamma + \beps) \notag\\
    &=  (\bX^\T \bX)^{-1} \bX^\T \mathbb{V}(\bX\bgamma + \beps) \bX  (\bX^\T \bX)^{-1} \label{eqn:variance}.
\end{align}
Under the assumption that environmental effects arise from a random process, $\bgamma \sim N(\boldsymbol{0}, p^{-1} \sigmagg I_p)$, equations \eqref{eqn:expectation} and \eqref{eqn:variance} yield $\mathbb{E}(\bbetaHat) = \bbeta$, and $\mathbb{V}(\bbetaHat) = p^{-1}\sigmagg\bI + \sigmaee (\bX^\T \bX)^{-1}$, respectively. Consider our earlier example involving confounding due to air quality. Simulating $\bgamma$ as a random quantity for each replication corresponds to subpopulation A being exposed to good air quality in one replication, and bad air quality in the next. Reporting the average across these situations is inconsistent with the question we are truly interested in, namely: what would happen if we took repeated samples from populations A and B, when these populations are subject to different environmental exposures? Those repeated samples would show a systematic bias due to the difference in air quality, but this is masked if $\bgamma$ is assumed to be random. Treating $\bgamma$ as a fixed quantity so that environmental effects are consistent across replications more closely approximates environmental confounding. Under the assumption that the quantity $\bgamma$ is fixed, equations \eqref{eqn:expectation} and \eqref{eqn:variance} yield $\mathbb{E}(\bbetaHat) = \bbeta + \bgamma, \mathbb{V}(\bbetaHat) = \sigmaee (\bX^\T \bX)^{-1}$, allowing us to quantify estimation bias due to environmental heterogeneity. 

Although we derive these quantities under model \eqref{eqn:lmm_reg}, where $\bZ = \bX$, these results also hold for the more general model \eqref{eqn:model}, where $\bZ \ne \bX$. We see this by decomposing $\bZ \bgamma$ into components in and orthogonal to the column space of the projection matrix of $\bX$. Define the projection matrix of $\bX$ by $\boldsymbol{P}_{\bX} = \bX (\bX^\T \bX)^{-1} \bX^\T$, and let $\mathcal{C}(\boldsymbol{P}_{\bX})$ and $\mathcal{N}(\boldsymbol{P}_{\bX})$ denote the column and null spaces of $\boldsymbol{P}_{\bX}$, respectively. Then, $\exists \boldsymbol{\tau, \psi}: \bZ \bgamma = \bX \boldsymbol{\tau + \psi}$ , $\boldsymbol{\tau} \in \mathcal{C}(\boldsymbol{P}_{\bX})$, and $\boldsymbol{\psi} \in \mathcal{N}(\boldsymbol{P}_{\bX})$ such that
\begin{align*}
    \by &= \bX\bbeta + \bZ\bgamma + \beps\\
    &= \bX\bbeta + \bX \boldsymbol{\tau} + \boldsymbol{\psi} + \beps\\
    &=  \bX \bbeta{^*} + \beps{^*}
\end{align*}
where $\boldsymbol{\tau}$ quantifies bias in the estimated $\bbetaHat{^\prime}$ and $\boldsymbol{\psi}$ is absorbed by the error term. In other words, any model specified in terms of $\bZ$ and $\bgamma$ is equivalent to a parameterization using $\bX$ and $\boldsymbol{\tau}$.

\anna{bring this back to why it may not matter if genetic similarity isn't a good proxy for population structure - in that case it's not a confounder anyway}

%------------------------------%
\subsection{Simulation study}
%------------------------------%
\subsubsection{Pseudophenotype generation}

Given the nature of environmental confounding in our setting of interest, and in order to assess these methodological performance in terms of estimation accuracy and bias specifically, we simulate according to a fixed $\bgamma$ framework using the following data-generating model
\begin{equation}
    \label{eqn:sim}
    \by = a \bX \bbeta + b \bZ \bgamma + c \beps,
\end{equation}
where $\by$ represents the pseudophenotype, and $a, b, c$ are scaling factors determined such that the variance of $\by$ is equal to 1 and is partitioned into genetic signal, environmental confounding, and random noise components,
\begin{equation}
    \label{eqn:parition_y}
    \mathbb{V}(\by) = \eta + (1 - \eta) \xi + (1-\eta)(1-\xi).
\end{equation}
$\eta$ defines the proportion of the variance of $\by$ attributable to additive genetic factors, commonly referred to as the narrow-sense heritability, $h^2 = \sigmagg/(\sigmagg + \sigmaee)$. $\eta$ also describes the data-generating model's signal to noise ratio (SNR). $\xi$ partitions the remaining variance of $\by$ into latent environmental heterogeneity and random noise. So, for example $\eta = 0.5$ and $\xi = 0.8$ corresponds to a 1:1 SNR, and means that 50\% of the variability in $\by$ is due to additive genetic effects, and 40\% due to environmental effects. \anna{more details about how/why this lambda selection method - cite CV as bad for LMMs, BIC not great bc different likelihoods... tie this into evaluating performance of each method in terms of variable selection} The $\lambda$ that allowed for the first 50 variables to enter the model was selected for each method. 1000 simulations were performed for each unique combination of parameters, datatype, subpopulation structure, and environmental effect structure. 

%This method for selecting $\lambda$ was chosen to fairly compare the 

%Cross-validation has generally been found to be inadvisable for penalized LMM methods \anna{cite thiiiiis}
%Using an information criterion such as BIC to select $\lambda$ is not comparable across methods since Lasso, PC-Lasso, LMM-Lasso-Rakitsch, and LMM-Lasso-ggmix methods each use a different likelihood.


\subsubsection{Design matrix generation}
We generated these pseudophenotypes using three types of high-dimensional ($p > n$) $\bX$ matrices: (1) simulated SNP data from independent subpopulations, (2) simulated SNP data from admixed subpopulations, and (3) real genome-wide SNP data from known caucasian ($n = 417$), African American ($n = 134$), and Hispanic ($n = 37$) subpopulations \anna{cite Vanderwas data}. $p = 1000$, $n = \{200, 400, 600, 800 \}$ for the simulated data types, and 50 causal SNPs were used throughout. 

\subsubsection{Subpopulation structure}
For the fully simulated data, two subpopulation structures were considered: (1) fine and (2) coarse. We define a coarse structure to be one characterized by a few large subpopulations intended to model large-scale environmental heterogeneity and population stratification, such as that described in our motivating air quaility example. Conversely, we define a fine subpopulation structure to be one characterized by many small subpopulations, or founding populations, which corresponds to a finer grained continuum of environmental heterogeneity. Whether fine or coarse, the simulated data were generated such that subpopulations, or founding populations, are of equal size. We note that the fine and coarse subpopulation structures are distinct from the level of admixture in the simulated data. For example, the discrete nonoverlapping subpopulations in the simulated independent subpopulation data result in an RRM which more directly corresponds to the discrete and fixed environmental effects, fine or coarse, than do the continuous and overlapping subpopulations in the simulated admixture data. The empirical data is comprised of three racial subpopulations; one relatively large, one small, and one in the middle. Thus it represents a hybrid of our simulated coarse and fine structures, with little apparent admixture. Supplementary Figures \anna{?, ?, and ?} illustrate the simulated kinship structures in the fine and coarse subpopulation settings, as well as that present in the empirical SNP data. 

\subsubsection{Structure of environmental effects}
For each $\bX$ matrix, $\bZ$ was a corresponding incidence matrix of 1s and 0s identifying subpopulation, or founding population membership, which assigns the corresponding environmental effect found in $\bgamma$. Various $\bgamma$ structures were considered in order to investigate the effects of various forms of environmental confounding. 

 Our initial hypothesis was that structures of $\bgamma$ that can be well-approximated by a linear combination of the observed genetic data would be well-approximated and corrected for by PC-Lasso, whereas LMM-Lasso may be more able to correct for subpopulation-specific effects that are nonlinear in nature and as such do not lend themselves to such an approximation. To that end we investigated two forms of environmental effect magnitudes: (1) exponential, and (2) dichotomous. In addition to the magnitudes of effects, we also considered whether individuals in genetically similar subpopulations would experience similar environmental effects. For example, a geographic environmental exposure such as the air quality described in our motivating example is likely to be similar among genetically related individuals due to concordance between genetic clusters and geography. However, behavior-based environmental exposures may be less likely to be shared by subpopulations which are genetically and geographically similar. As an example, \citet{ng2014smoking} found considerable within-region variation in smoking rates in Africa, Asia, and South America.

 To evaluate the performance of penalized LMM methods in both scenarios, we consider exponential and dichotomous effect magnitudes with are concordant or discordant in nature, for a total of four distinct $\bgamma$ structures. We define concordant effects as those that are similar among genetically similar subpopulations, and discordant effects as those that are not. Figure \ref{fig:gamma_structures} displays a visual summary of these four coefficient structures. 
\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.9]{figures/gamma_structure.png}
    \caption{$\bgamma$ structures}
    \label{fig:gamma_structures}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results} \label{sec:results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%------------------------------%
\subsection{PC-Lasso and LMM-Lasso outperform Lasso in the presence of environmental confounding}
%------------------------------%

We begin by comparing the ordinary lasso, PC-Lasso, and LMM-Lasso as the level of environmental confounding is varied. Estimation accuracy for lasso, PC-Lasso, and LMM-Lasso was evaluated based on mean squared error (MSE) in various settings and broken down into bias and variance components.  Figure \ref{fig:mse} presents these results for all three data types in a 1:1 signal to noise (SNR) setting, where $\eta = 0.5$. The top row of Figure \ref{fig:mse} shows that when $\xi = 0$ (i.e., no environmental confounding), lasso and LMM-Lasso perform comparably. PC-Lasso results in a slight inflation in MSE compared to the other methods due to the fact that 10 additional predictors have been added to the model, but none of them actually explain any variability in the outcome. The bottom row of Figure \ref{fig:mse} shows the MSE when $\xi = 0.8$. In this case, both PC-Lasso and LMM-Lasso clearly outperform the naive lasso. This improvement is more substantial in the independent subpopulations simulated data than the admixed simulated data. This is due to the fact that the discrete, nonoverlapping genetic subpopulations more directly correspond to the distinct fixed environmental effects than do the more continuous and blended subpopulations in the admixture data.

\anna{in admixed data less of the environmental effect is in the column space of X so it's less of a confounder}

\begin{figure}[H]
    \centering
    \includegraphics[scale = 1.1]{figures/beta_mse.png}
    \caption{Estimation accuracy of different methods for different data types in the presence and absence of environmental confounding with coarse subpopulation structure and dichotomous-discordant environmental effects.}
    \label{fig:mse}
\end{figure}

%------------------------------%
\subsection{LMM-Lasso outperforms PC-Lasso in the presence of fine subpopulation structure}
%------------------------------%

Given the superior performance of PC-Lasso and LMM-Lasso compared to the naive lasso in the presence of environmental confounding, we next compare these methods in the presence of fine and coarse subpopulation structures. Phenotypes were simulated using a 1:1 SNR, $\eta = 0.5$, and varying levels of environmental confounding, $\xi \in \{0, 0.2, 0.5,0.8\}$. Figure \ref{fig:big_vs_small} summarizes the results of these simulations for the independent subpopulation simulated $\bX$ with environmental confounding generated using a dichotomous-discordant $\bgamma$ structure, though qualitatively similar results were observed for the other data types and $\gamma$ structures. The y-axis displays the difference in MSE (PC-Lasso - LMM-Lasso) for each simulation and for the various subpopulation structures. The dashed horizontal line at 0 indicates no difference in the performance of PC-Lasso and LMM-Lasso, while differences greater than 0 correspond to smaller MSE for LMM-Lasso, and thus superior estimation accuracy. 

In the presence of coarse population structure, there is some overlap in the estimation accuracy of PC-Lasso and LMM-Lasso, as evidenced by the corresponding boxes straddling the 0 line. However, the majority of these boxes fall above 0, particularly for lower $\eta$ values, indicating the superior performance of LMM-Lasso. In the presence of fine population structure, LMM-Lasso is clearly superior to PC-Lasso in estimation accuracy. This is consistent with \citet{hoffman2013correcting}, who showed that principal component adjustment methods represent a low dimensional approximation to linear mixed models. As such, it is reasonable that PC-Lasso, which corrects for population structure using a low dimensional set of surrogate variables, would perform reasonably well in the coarse subpopulation setting, but fall short in the presence of fine structure. 
\begin{figure}[H]
    \centering
    % \includegraphics[scale = 0.9]{figures/mse_diff_subpops}
     \includegraphics[scale = 0.9]{figures/mse_diff_subpops.png}
    \caption{Relative performance of LMM-Lasso, PC-Lasso for fine and coarse subpopulation structures and varying levels of environmental confounding with independent subpopulation data, $\eta = 0.5$, and dichotomous-discordant environmental effects.}
    \label{fig:big_vs_small}
\end{figure}


%------------------------------%
\subsection{LMM-Lasso outperforms PC-Lasso when environmental effects are discordant}
%------------------------------%

In addition to evaluating PC-Lasso and LMM-Lasso in the presence of coarse and fine subpopulation structure, we also consider distinct patterns of environmental effects. Figure \ref{fig:big_small_gamma} shows the difference in MSE (PC-Lasso - LMM-Lasso) broken down by both subpopulation and coefficient structure. Results are shown for phenotypes generated with $\eta = 0.5$, $\xi = 0.8$, and the independent subpopulation simulated $\bX$. The right-hand panels of Figure \ref{fig:big_small_gamma} are consistent with Figure \ref{fig:big_vs_small}, showing superior LMM-Lasso performance in the presence of fine subpopulation structure, regardless of coefficient magnitude or concordance. The upper left hand panel of Figure \ref{fig:big_small_gamma} corresponds to coarse subpopulation structure with discordant coefficients and also appears to be a setting where LMM-Lasso outperforms PC-Lasso, regardless of coefficient magnitude, although there is some overlap with PC-Lasso. The lower left hand panel of Figure \ref{fig:big_small_gamma} shows results for the setting of coarse supopulation structure with concordant coefficients. In this setting, PC-Lasso and LMM-Lasso perform comparably in the presence of exponential-concordant environmental effects, while PC-Lasso outperforms LMM-Lasso in the majority of dichotomous-concordant environmental effects. These findings are in line with our initial hypothesis that PC-Lasso will perform well in the presence of environmental effects that can be well-approximated by a linear combination of the observed data. When that is not the case, either due to the presence of fine subpopulation structure, nonlinear environmental effects, or genetic similarity that does not reflect similar environmental effects, LMM-Lasso exhibits estimation accuracy superior to that of PC-Lasso.

\begin{figure}[H]
    \centering
    % \includegraphics[scale = 0.9]{figures/fig2b.png}
    \includegraphics[scale = 0.9]{figures/mse_diff_hetero.png}
    \caption{Relative performance of LMM-Lasso, PC-Lasso for fine and coarse subpopulation structures and varying environmental effect structures with independent subpopulation data, $\eta = 0.5$, and $\xi = 0.8$}
    \label{fig:big_small_gamma}
\end{figure}

%------------------------------%
\subsection{Different implementations of LMM-Lasso}
%------------------------------%

In section \ref{sec:rak-ggmix} we briefly mentioned the existence of two LMM-Lasso variants: LMM-Lasso-Rakitsch and LMM-Lasso-ggmix. As we will see, the two generally perform quite similarly. Thus, the preceding results, although based on the LMM-Lasso-Rakitsch implementation, are representative of both LMM-Lasso methods. The primary purpose of this review is to compare LMM-Lasso to other penalized regression methods with respect to correcting for population structure and environmental confounding. However, given the generally strong performance of LMM-Lasso, we also wish to discuss the key differences between these two implementations and provide guidance for potential users.

LMM-Lasso-Rakitsch estimates the variance components once, under the assumption of a null model. LMM-Lasso-ggmix seeks to improve upon this by re-estimating the variance components and $\bbeta$ iteratively. Although this seems a reasonable approach, we have been unable to find a scenario where LMM-Lasso-ggmix outperforms the LMM-Lasso-Rakitsch in estimation accuracy of $\bbeta$. Figure \ref{fig:eta_beta_mse} shows the MSE for estimation of both $\bbeta$ and $\eta$ in the presence of varying $\eta$ values and sample sizes, $n$, for both LMM-Lasso-Rakitsch and LMM-Lasso-ggmix. The bottom panel of this figure shows a modest improvement in the estimation of $\eta$ for the LMM-Lasso-ggmix method, particularly in the presence of lower $\eta$ values. However, these apparent improvements in estimating $\eta$ do not improve the $\bbeta$ estimation accuracy of LMM-Lasso-ggmix. This is evidenced by the top panel of Figure \ref{fig:eta_beta_mse}, which shows nearly identical performances of both methods in terms of $\bbeta$ MSE. 

\begin{figure}[H]
    \centering
    \includegraphics[scale = 1]{figures/eta_beta_hat.png}
     \caption{$\bbeta$ and $\eta$ estimation accuracy of LMM-Lasso-Rakitsch and LMM-Lasso-ggmix for varying $\eta$ levels and sample sizes with independent subpopulation data, coarse subpopulation structure, $\xi = 0.8$, and dichotomous-discordant environmental effect structure.}
    \label{fig:eta_beta_mse}
\end{figure}
\anna{add time to this figure? third row...}


\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.8]{figures/time_ratio.png}
    \caption{Computing time of LMM-Lasso-Rakitsch compared with that of LMM-Lasso-ggmix for varying sample sizes with independent subpopulation structure, coarse subpopulation structure, $\eta = 0.5$, $\xi = 0.8$, and dichotomous-discordant environmental effect structure.}
    \label{fig:time}
\end{figure}
\anna{Note Figure \ref{fig:time} is on raw scale, not log10. This is because the negative values on the error bars create problems and become NaN on the log10 scale}

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.8]{figures/time_ratio_box.png}
    \caption{\anna{Alternate time fig} Computing time of LMM-Lasso-Rakitsch compared with that of LMM-Lasso-ggmix for varying sample sizes with independent subpopulation structure, coarse subpopulation structure, $\eta = 0.5$, $\xi = 0.8$, and dichotomous-discordant environmental effect structure.}
    \label{fig:time_box}
\end{figure}


\anna{make new time box plot - two boxes instead of ratio - also run for n = 1000, 1200, maybe 1400 and show MSE along with time... compare convergence results to ncvfit}

In addition, we have found that LMM-Lasso-ggmix performs poorly in a low-dimensional setting due to the ill-conditioning of the RRM. Given its intended use for the analysis of high-dimensional data, this fact could be of little consequence to practitioners. However, although its estimation accuracy in high dimensions is on par with that of LMM-Lasso-Rakitsch, as shown in Figure \ref{fig:eta_beta_mse}, this is also a setting in which the computational time required may be prohibitive for practical applications. \anna{time interpretation depends on reason ggmix is slow...} Figure \ref{fig:time} shows the ratio of computing time required for LMM-Lasso-ggmix compared to that of LMM-Lasso-Rakitsch, for various sample sizes. The horizontal dashed line at 1 indicates both methods require the same computing time. Despite its comparable performance in accurately estimating $\bbetaHat$, LMM-Lasso-ggmix takes requires an average of \anna{73.4} times the computing time of LMM-Lasso-Rakitsch. Thus, LMM-Lasso-Rakitsch seems to be a more attractive and scalable method than LMM-Lasso-ggmix.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion} \label{sec:discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this work, we have reviewed the concept of population stratification and explicitly defined the environmental mechanism by which it may confound the genotype-phenotype relationship. We have provided a broad outline of existing methods for ameliorating the effects of these unobserved confounding influences. In addition, we have provided a thorough review of two popular approaches for correcting for population structure in genetic data: PC-Lasso and LMM-Lasso. 

We have detailed the assumptions made by PC-Lasso and LMM-Lasso, which model confounding influences as fixed and random effects, respectively. We have also described the ways in which simulation schemes to evaluate these methods may fail to accurately capture the effects of environmental heterogeneity. In turn, we propose and utilize a simulation approach in which the estimation bias introduced by environmental heterogeneity may be evaluated. We then compare the estimation accuracy of a \anna{naive} Lasso, PC-Lasso, and LMM-Lasso in various confounding scenarios.

Unsurprisingly, we find that PC-Lasso and LMM-Lasso outperform the \anna{naive} Lasso whenever environmental confounding effects are present. However, in the absence of such effects, PC-Lasso may hinder estimation accuracy and perform more poorly than even the \anna{naive} Lasso. This is due to the fact that the principal components are unpenalized and thus included in the final model, even when they do more harm than good in explaining phenotypic variability. Additionally, we find that LMM-Lasso outperforms PC-Lasso when (1) fine subpopulation structure is present and (2) when confounding effects are nonlinear and discordant in nature. In the presence of coarse subpopulation structure which corresponds to concordant, dichotomous environmental effects, PC-Lasso may outperform LMM-Lasso in estimation accuracy. However, LMM-Lasso is more robust to subpopulation structure as well as nonlinear and discordant environmental effects. Therefore, LMM-Lasso is a more robust method for practitioners seeking to obtain unbiased estimates when the exact nature of the population structure and corresponding environmental heterogeneity are unknown.  

Finally, we considered two implementations of the LMM-Lasso method: LMM-Lasso-Rakitsch and LMM-Lasso-ggmix, which differ in their variance estimation procedures and computational implementations. Although we found that both methods perform similarly in terms of $\bbeta$ estimation accuracy, LMM-Lasso-ggmix has several drawbacks. Firstly, it suffers from instability in low dimensions. \anna{depends on ggmix time results} Secondly, although LMM-Lasso-Rakitsch and LMM-Lasso-ggmix perform comparably in high dimensions, LMM-Lasso-ggmix requires an average of 73.4 and as much as 167.57 \anna{73.4 is the mean ratio + sd, but the max absolute ratio is 167.57 - which should I report?} times the computing time of LMM-Lasso-Rakitsch due to its iterative estimation procedure. Thirdly, while the additional time required of LMM-Lasso-ggmix may be worthwhile if it yielded more accurate estimates of $\eta$, or narrow-sense heritability, we have been unable to identify a scenario where its narrow-sense heritability estimates are greatly superior to those of LMM-Lasso-Rakitsch. We have implemented the LMM-Lasso-Rakitsch method using the equivalent, but more interpretable, $\eta$ paramaterization in the \texttt{R} package, \texttt{penalizedLMM (final name tbd)}, available on the author's github page: \url{https://github.com/areisett/penalizedLMM}.

\pb{Introduce penalizedLMM here, or in next paper?}

It is worth nothing that even in scenarios where LMM-Lasso outperforms other methods, its estimation accuracy still suffers due to the bias inherent in penalized regression methods. Because of this, bias-reduction techniques for penalized LMMs are an attractive avenue for future research.


\anna{the importance of distinguishing between population structure and heterogeneous environmental exposures in penalized regression methods - do we want to get into the importance of not conflating environmental effects with heritability?}

